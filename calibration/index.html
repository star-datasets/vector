<!DOCTYPE html>
<html lang="en">

  <!-- Head -->
  <head>    <!-- Metadata, OpenGraph and Schema.org -->
    

    <!-- Standard metadata -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>VECtor Benchmark   | Calibration</title>
    <meta name="author" content="VECtor Benchmark  " />
    <meta name="description" content="A Versatile Event-Centric Benchmark for Multi-Sensor SLAM.
" />
    <meta name="keywords" content="VECtor Benchmark, Event-based, Multi-Sensor, Dataset" />

    <!-- OpenGraph -->
    <meta property="og:site_name" content="VECtor Benchmark  " />
    <meta property="og:type" content="website" />
    <meta property="og:title" content="VECtor Benchmark   | Calibration" />
    <meta property="og:url" content="http://localhost:4000/vector/calibration/" />
    <meta property="og:description" content="A Versatile Event-Centric Benchmark for Multi-Sensor SLAM.
" />
    
    <meta property="og:locale" content="en" />

    <!-- Twitter card -->
    <meta name="twitter:card" content="summary" />
    <meta name="twitter:title" content="Calibration" />
    <meta name="twitter:description" content="A Versatile Event-Centric Benchmark for Multi-Sensor SLAM.
" />
    
    

    <!-- Schema.org -->
    <script type="application/ld+json">
      {
        "author":
        {
          "@type": "Person",
          "name": "VECtor Benchmark  "
        },
        "url": "http://localhost:4000/vector/calibration/",
        "@type": "WebSite",
        "description": "A Versatile Event-Centric Benchmark for Multi-Sensor SLAM.
",
        "headline": "Calibration",
        "sameAs": ["https://github.com/MobilePerceptionLab", "https://mpl.sist.shanghaitech.edu.cn/"],
        "name": "VECtor Benchmark  ",
        "@context": "https://schema.org"
      }
    </script>


    <!-- Bootstrap & MDB -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous" />

    <!-- Fonts & Icons -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous">
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

    <!-- Code Syntax Highlighting -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/PASTIE.css" media="none" id="highlight_theme_light" />

    <!-- Styles -->
    
    <link rel="shortcut icon" href="/vector/assets/img/mpl_icon.png"/>
    
    <link rel="stylesheet" href="/vector/assets/css/main.css">
    <link rel="canonical" href="http://localhost:4000/vector/calibration/">
    
    <!-- Dark Mode -->
    

  </head>

  <!-- Body -->
  <body class="fixed-top-nav ">

    <!-- Header -->
    <header>

      <!-- Nav Bar -->
      <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
        <div class="container">
          <a class="navbar-brand title font-weight-lighter" href="http://localhost:4000/vector/"><span class="font-weight-bold">VECtor Benchmark</span>   </a>
          <!-- Navbar Toggle -->
          <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar top-bar"></span>
            <span class="icon-bar middle-bar"></span>
            <span class="icon-bar bottom-bar"></span>
          </button>

          <div class="collapse navbar-collapse text-right" id="navbarNav">
            <ul class="navbar-nav ml-auto flex-nowrap">

              <!-- Home -->
              <li class="nav-item ">
                <a class="nav-link" href="/vector/">Home</a>
              </li>

              <!-- Remove Blog || Publications || Projects button on the header -->
              <!--  -->
              <!-- Blog -->
              <!-- <li class="nav-item ">
                <a class="nav-link" href="/vector/blog/">blog</a>
              </li> --> 

              <!-- Other pages -->
                <li class="nav-item dropdown ">
                  <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">About</a>
                  <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown">
                    <a class="dropdown-item" href="/vector/about/sensor/">Sensor Suite</a>
                    <div class="dropdown-divider"></div>
                    <a class="dropdown-item" href="/vector/about/synchronization/">Synchronization</a>
                    <div class="dropdown-divider"></div>
                    <a class="dropdown-item" href="/vector/about/ground_truth/">Ground Truth</a>
                  </div>
                </li>
                <li class="nav-item active">
                  <a class="nav-link" href="/vector/calibration/">Calibration<span class="sr-only">(current)</span></a>
                </li>
                <li class="nav-item ">
                  <a class="nav-link" href="/vector/download/">Download</a>
                </li>
                <li class="nav-item ">
                  <a class="nav-link" href="/vector/competition/">Competition</a>
                </li>
                <li class="nav-item dropdown ">
                  <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">Contact Us</a>
                  <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown">
                    <a class="dropdown-item" href="mailto:gaoling@shanghaitech.edu.cn">Calibration Issue</a>
                    <div class="dropdown-divider"></div>
                    <a class="dropdown-item" href="mailto:gaoling@shanghaitech.edu.cn">Dataset Issue</a>
                  </div>
                </li>
            </ul>
          </div>
        </div>
      </nav>
    </header>

    <!-- Content -->
    <div class="container mt-5">
      <!-- page.html -->
        <div class="post">

          <header class="post-header">
            <h1 class="post-title">Calibration</h1>
            <p class="post-description"></p>
          </header>

          <article>
            <p><br></p>

<div class="row">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    <source media="(max-width: 480px)" srcset="/vector/assets/img/calibration-480.webp"></source>
    <source media="(max-width: 800px)" srcset="/vector/assets/img/calibration-800.webp"></source>
    <source media="(max-width: 1400px)" srcset="/vector/assets/img/calibration-1400.webp"></source>
    <!-- Fallback to the original file -->
    <img class="img-fluid rounded z-depth-1" src="/vector/assets/img/calibration.png" title="calibration">

  </picture>

</figure>

    </div>
</div>
<div class="caption" style="text-align:left;">
Illustration of required calibration variables. Nodes: sensor type (yellow/void background color indicates need/no need for intrinsic calibration). Blue edges: joint extrinsic camera calibration. Cyan edges: IMU-camera extrinsic calibration. Orange edges: MoCap-camera hand-eye calibration. Red edges: LiDAR-camera extrinsic calibration. Note that the
latter three use the regular stereo camera extrinsics as hard constraints during optimization. The variables are calibrated in the listed order.
</div>

<p><br></p>

<h4>Intrinsics</h4>

<p><br></p>

<p>All camera intrinsics, including the focal lengths, the optical center, and the distortion parameters, are calibrated using the official <a href="http://wiki.ros.org/camera_calibration" target="_blank" rel="noopener noreferrer">ROS Camera Calibration toolbox</a> and by gently moving in front of a 9 x 6 checkerboard visualized on a computer screen. The choice of a virtual checkerboard enables display in either static or blinking mode. The latter is particularly useful for event camera calibration, as it produces accumulated event images with a sharp appearance of the checkerboard. Images that contain too much blur have been manually removed. Note that we take the factory calibration result for the RGB-D sensor (intrinsics of both color and depth camera as well as extrinsics between them).</p>

<p>The IMU intrinsics (i.e. the statistical properties of the accelerometer and gyroscope signals, including bias random walk and noise densities) are calibrated using the <a href="https://github.com/ori-drs/allan_variance_ros" target="_blank" rel="noopener noreferrer">Allan Variance ROS toolbox</a> with a 5-hour-long IMU sequence by putting the sensor flat on the ground with no perturbation. The MoCap system is pre-calibrated before data recording.</p>

<!-- - **Left Event Camera Intrinsic**: data sequences, calibration results
- **Right Event Camera Intrinsic**: data sequences, calibration results
- **Left Regular Camera Intrinsic**: data sequences, calibration results
- **Right Regular Camera Intrinsic**: data sequences, calibration results
- **RGB-D Color Camera Intrinsic**: factory calibration results
- **RGB-D Depth Camera Intrinsic**: factory calibration results
- **IMU Intrinsic**: data sequences, calibration results -->

<p><br></p>

<h4>Joint extrinsic camera calibration</h4>

<p><br></p>

<p>In order to determine the extrinsics of the multi-camera system, we point the sensor setup towards the screen and record both static and blinking checkerboard patterns with known size. For each observation, the relative position between screen and sensors is kept still by putting the sensor suite steadily on a tripod. The board is maintained within the field of view of all cameras. Note that here we use the color camera on the RGB-D sensor to jointly calibrate its extrinsics. The extrinsics of the depth camera are obtained by the known internal parameters of the depth camera, and the rolling shutter effect is safely ignored as no motion between cameras and pattern is involved. The extrinsics are calculated by detecting corner points on the checkerboard pattern and applying PnP to the resulting 2D-3D correspondences. The result is refined by <a href="http://ceres-solver.org/" target="_blank" rel="noopener noreferrer">Ceres Solver</a>-based reprojection error minimization. We finally validate the estimated extrinsic parameters by analyzing the quality of depth map reprojections and by comparing the result against the measurements from the CAD model.</p>

<!-- - **RGB-D Extrinsic (small-scale)**: factory calibration results
- **Joint Camera Extrinsics (CAD model)**: CAD readings
- **Joint Camera Extrinsics (small-scale)**: data sequences, calibration results 
- **Joint Camera Extrinsics (large-scale)**: data sequences, calibration results -->

<p><br></p>

<h4>Camera-IMU extrinsic calibration</h4>

<p><br></p>

<p>Extrinsic transformation parameters between the IMU and the regular stereo camera are identified using the <a href="https://github.com/ethz-asl/kalibr" target="_blank" rel="noopener noreferrer">Kalibr toolbox</a>. The visual-inertial system is directed towards a static 6 x 6 April-grid board, and the board is constantly maintained within the field of view of both regular cameras. All six axes of the IMU are properly excited, and the calibration is conducted under good illumination conditions to further reduce the unwanted side-effects of motion blur. Given prior intrinsics of the regular stereo camera and the IMU and extrinsics between the regular cameras, we limit the calculation to the extrinsics between the IMU and the regular stereo camera, only.</p>

<!-- - **Camera-IMU Extrinsics (CAD model)**: CAD readings
- **Camera-IMU Extrinsics (small-scale)**: data sequences, calibration results
- **Camera-IMU Extrinsics (large-scale)**: data sequences, calibration results -->

<p><br></p>

<h4>Camera-MoCap hand-eye calibration</h4>

<p><br></p>

<p>The MoCap system outputs position measurements of the geometric centers of all markers expressed in a MoCap-specific reference frame. In order to compare recovered trajectories against ground truth, we therefore need to identify a euclidean transformation between the MoCap frame of reference and any other sensor frame. A static 7 x 6 checkerboard is maintained within the field of view of both gently-moving cameras, and MoCap pose measurements are simultaneously recorded. Relative poses from both the MoCap system and the cameras are then used to solve the hand-eye calibration problem using the official <a href="https://docs.opencv.org/3.4/d9/d0c/group__calib3d.html" target="_blank" rel="noopener noreferrer">OpenCV calibrateHandEye API</a>.</p>

<!-- - **Camera-MoCap Extrinsics (small-scale)**: data sequences, calibration results -->

<p><br></p>

<h4>Camera-LiDAR extrinsic calibration</h4>

<p><br></p>

<p>Our extrinsic calibration between the LiDAR and the cameras bypasses via a high-quality colored point cloud captured by a FARO scanner. The point cloud is captured in an unfurnished room with simple geometric structure and in which we only place a checkerboard. In order to perform the extrinsic calibration, we then record LiDAR scans and corresponding camera images by moving the sensor setup in this room. The cameras are constantly directed at the checkerboard. Next, we estimate the transformation between the FARO and the LiDAR coordinate frames by point cloud registration. Owing to the fact that the FARO scan is very dense and colored, we can furthermore hand-pick 3D points corresponding to checkerboard corners in the real world. By furthermore detecting those points in the camera images, we can again run the PnP method to obtain FARO to camera transformations. To conclude, the extrinsic parameters between LiDAR and cameras are retrieved by concatenating the above two transformations.</p>

<!-- - **Camera-LiDAR Extrinsics (CAD model)**: CAD readings
- **Camera-LiDAR Extrinsics (large-scale)**: data sequences, calibration results -->

<p><br></p>

<h4>Calibration Toolbox</h4>

<p><br></p>

<p>Calibration toolbox will be released in due time.</p>

          </article>

        </div>

    </div>

    <!-- Footer -->    
    <footer class="fixed-bottom">
      <div class="container mt-0" style="width:100%;text-align:center;">
        Â© 2022 Mobile Perception Lab, ShanghaiTech University, China. All rights reserved.

        <!-- &copy; Copyright 2022 VECtor Benchmark  . All rights reserved.
 -->
      </div>
    </footer>

    <!-- JavaScripts -->
    <!-- jQuery -->
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>

    <!-- Bootsrap & MDB scripts -->
  <script src="https://cdn.jsdelivr.net/npm/@popperjs/core@2.11.2/dist/umd/popper.min.js" integrity="sha256-l/1pMF/+J4TThfgARS6KwWrk/egwuVvhRzfLAMQ6Ds4=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.min.js" integrity="sha256-SyTu6CwrfOhaznYZPoolVw2rxoY7lKYKQvqbtqN93HI=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script>

    <!-- Masonry & imagesLoaded -->
  <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
  <script defer src="/vector/assets/js/masonry.js" type="text/javascript"></script>
    
  <!-- Medium Zoom JS -->
  <script src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script>
  <script src="/vector/assets/js/zoom.js"></script><!-- Load Common JS -->
  <script src="/vector/assets/js/common.js"></script>

    <!-- MathJax -->
  <script type="text/javascript">
    window.MathJax = {
      tex: {
        tags: 'ams'
      }
    };
  </script>
  <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
  <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>

    
  </body>
</html>

